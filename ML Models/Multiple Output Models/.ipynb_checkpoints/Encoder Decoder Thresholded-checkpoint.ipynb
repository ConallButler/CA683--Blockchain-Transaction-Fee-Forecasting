{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {},
   "source": [
    "# Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {},
   "source": [
    "We are training a seperate model for each timestep in the lookahead window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bf1274bf-8a6d-4c0a-89f6-71c2ba88d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "455294aa-fc95-488a-89d1-10ff6bf74edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4062596 ],\n",
       "       [0.3939888 ],\n",
       "       [0.37343547],\n",
       "       [0.36600208],\n",
       "       [0.36458609],\n",
       "       [0.36393437],\n",
       "       [0.36196753],\n",
       "       [0.35879064],\n",
       "       [0.3547461 ],\n",
       "       [0.3505047 ],\n",
       "       [0.34662616],\n",
       "       [0.34320158],\n",
       "       [0.3404048 ],\n",
       "       [0.33821583],\n",
       "       [0.33664936],\n",
       "       [0.33556545],\n",
       "       [0.3348277 ],\n",
       "       [0.33446702],\n",
       "       [0.33435377],\n",
       "       [0.33436394]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples():\n",
    "    #Load data as float, datetime to index\n",
    "    data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    data = data.set_index('datetime')\n",
    "    data = data.squeeze()\n",
    "    data = data.astype('float')\n",
    "\n",
    "    #Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "    data = data.resample(resample_rate).mean()\n",
    "\n",
    "    #Add 24hr lag for min gas price\n",
    "    data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "    data = data[288:]\n",
    "\n",
    "    #Convert to gwei\n",
    "    data = data.apply(lambda x: x/1000000000)\n",
    "    data =data[inputs]\n",
    "\n",
    "    #Filter inputs\n",
    "    data =data[inputs]\n",
    "    scaler = MinMaxScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    y = y[:, :, :1]\n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d8e23f-0232-4580-abc7-f2bae6d359e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "start_date='2021-11-26 00:00:00'\n",
    "end_date='2022-01-26 23:55:00' \n",
    "inputs = ['min_gas_price', 'max_gas_price', 'min_gas_price_24hr_lag', 'Open']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in =  2016\n",
    "n_steps_out = 20\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095b220a-aabf-4ec1-a280-db969a29e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = generate_training_val_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f07cd239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 91s 678ms/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 70s 643ms/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 70s 645ms/step - loss: 9.7838e-04 - val_loss: 0.0017\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 71s 650ms/step - loss: 9.1279e-04 - val_loss: 0.0016\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 70s 645ms/step - loss: 8.9783e-04 - val_loss: 0.0016\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 71s 648ms/step - loss: 8.6649e-04 - val_loss: 0.0016\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 70s 642ms/step - loss: 8.5978e-04 - val_loss: 0.0020\n",
      "Epoch 8/10\n",
      "109/109 [==============================] - 70s 645ms/step - loss: 8.5521e-04 - val_loss: 0.0017\n",
      "Epoch 9/10\n",
      "109/109 [==============================] - 70s 645ms/step - loss: 8.3249e-04 - val_loss: 0.0016\n",
      "Epoch 10/10\n",
      "109/109 [==============================] - 70s 646ms/step - loss: 8.3623e-04 - val_loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17868505910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs))))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=10, verbose=1, batch_size=100, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4a79ee3c-c389-4517-90c3-66dac8d51201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder_decoder_20\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder_decoder_20\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017838229FD0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001783C23FDC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001783C4B5E80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001783C733E80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001783C671700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000178529D1EB0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017852AB7190> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000017852F90EE0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001785303CF40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('encoder_decoder_20')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3aaef",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0ec655c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96be238-7c7e-45d2-b963-d4d0519a03a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 40s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e9f503f6-a6ca-411c-acd5-ba023681d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5628682334342274"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i =3\n",
    "r2_score(y_val[i], yhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f745f51a-7fab-4cf1-b5a2-dd422e381f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics(y_val, y_pred):\n",
    "    RMSE = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    MAE = mean_absolute_error(y_val, y_pred)\n",
    "    MAPE = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    R2 = r2_score(y_val, y_pred)\n",
    "    MSE = mean_squared_error(y_val, y_pred)\n",
    "    return RMSE, MAE, MAPE, R2, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bed69-a202-4889-b334-488d430fbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our min max scaler so we can revert transform\n",
    "#Load data as float, datetime to index\n",
    "data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('datetime')\n",
    "data = data.squeeze()\n",
    "data = data.astype('float')\n",
    "\n",
    "#Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "data = data.resample(resample_rate).mean()\n",
    "\n",
    "#Add 24hr lag for min gas price\n",
    "data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "data = data[288:]\n",
    "\n",
    "#Convert to gwei\n",
    "data = data.apply(lambda x: x/1000000000)\n",
    "data =data[inputs]\n",
    "\n",
    "#Filter inputs\n",
    "data =data[inputs]\n",
    "scaler = MinMaxScaler()\n",
    "data[inputs] = scaler.fit_transform(data[inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b642b42e-5bc7-4790-a0da-d8ce69161c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "for i in range(0, len(y_val)):\n",
    "    pred_descaled= (scaler.inverse_transform(array([yhat[i],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    val_descaled= (scaler.inverse_transform(array([y_val[i],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    RMSE, MAE, MAPE, R2, MSE = return_metrics((val_descaled*1000000000), (pred_descaled*1000000000))\n",
    "    RMSE_list.append(RMSE)\n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "    R2_list.append(R2)\n",
    "    MSE_list.append(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "be1019c2-8725-4d6a-a35c-9faa858484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_RMSE 41.52602139585727\n",
      "mean_MAE 32.19459305537631\n",
      "mean_MAPE 0.21347540999212844\n",
      "mean_R2 -2.828470045502426\n",
      "mean_MSE 3207.006911456973\n"
     ]
    }
   ],
   "source": [
    "print('mean_RMSE ' + str(mean(RMSE_list))) \n",
    "print('mean_MAE ' + str(mean(MAE_list))) \n",
    "print('mean_MAPE ' + str(mean(MAPE_list)))\n",
    "print('mean_R2 ' + str(mean(R2_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "406b51f4-6d11-4c9f-8c9a-3764038c54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_descaled= (scaler.inverse_transform(array([yhat[i],]*(len(inputs))).transpose()[0]))[:, :1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71867c-b942-43c5-ba9e-d5144cf1432a",
   "metadata": {},
   "source": [
    "## We need to define the min max scaler outside of the fucntion so we can revert the transform;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9c77119-20c0-4772-8379-f4480a7f3621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " #Load data as float, datetime to index\n",
    "data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('datetime')\n",
    "data = data.squeeze()\n",
    "data = data.astype('float')\n",
    "\n",
    "#Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "data = data.resample(resample_rate).mean()\n",
    "\n",
    "#Add 24hr lag for min gas price\n",
    "data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "data = data[288:]\n",
    "\n",
    "#Convert to gwei\n",
    "data = data.apply(lambda x: x/1000000000)\n",
    "data =data[inputs]\n",
    "\n",
    "#Filter inputs\n",
    "data =data[inputs]\n",
    "scaler = MinMaxScaler()\n",
    "data[inputs] = scaler.fit_transform(data[inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "546dc7bc-5d82-412f-aa25-90a5d928b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_descaled= (scaler.inverse_transform(array([y_val[500],]*(len(inputs))).transpose()[0]))[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca2d6008-80e1-418b-a96c-565aaefb868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.11242359e-07],\n",
       "       [1.18691171e-07],\n",
       "       [1.33244900e-07],\n",
       "       [1.26157250e-07],\n",
       "       [1.24670228e-07],\n",
       "       [1.13491306e-07],\n",
       "       [1.32589433e-07],\n",
       "       [1.02599717e-07],\n",
       "       [1.21456117e-07],\n",
       "       [1.49649458e-07],\n",
       "       [1.74153241e-07],\n",
       "       [1.16743730e-07],\n",
       "       [1.46191195e-07],\n",
       "       [1.22619740e-07],\n",
       "       [1.27602427e-07],\n",
       "       [1.30021617e-07],\n",
       "       [1.32395453e-07],\n",
       "       [1.26484093e-07],\n",
       "       [1.19207119e-07],\n",
       "       [1.24028573e-07]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_descaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716123c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27892/1015516839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Minmax scaler has been fit with nd data, add dummy columns so the scaler can be applied to min gas rpice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred_descaled\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgroud_truth_descaled\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         X = check_array(\n\u001b[0m\u001b[0;32m    526\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    792\u001b[0m                 ) from e\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    795\u001b[0m                 \u001b[1;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m                 \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "#Minmax scaler has been fit with nd data, add dummy columns so the scaler can be applied to min gas rpice\n",
    "pred_descaled= (scaler.inverse_transform(array([yhat,]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "groud_truth_descaled= (scaler.inverse_transform(array([y_val,]*(len(inputs))).transpose()[0][0]))[ :, :1]\n",
    "\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(15)\n",
    "ax1.plot(pred_descaled)\n",
    "ax1.title.set_text('Gas Price Prediction')\n",
    "ax2.plot(groud_truth_descaled)\n",
    "ax2.title.set_text('Gas Price Actual')\n",
    "\n",
    "\n",
    "ax3.title.set_text('Overlayed')\n",
    "ax3.plot(groud_truth_descaled, color='blue',label='Predicted '+' Gas Price')\n",
    "ax3.plot(pred_descaled, color='red',label='real '+' Gas Price')\n",
    "\n",
    "\n",
    "\n",
    "print('RMSE ' + str(mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)))\n",
    "print('MAE ' + str(mean_absolute_error(groud_truth_descaled, pred_descaled)))\n",
    "print('MAPE ' + str(mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)))\n",
    "print('R^2 ' + str(r2_score(groud_truth_descaled, pred_descaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a108b8cb-ee07-4b4c-84ea-8b972403e6f8",
   "metadata": {},
   "source": [
    "## Lets look at the metrics for all lookaheads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00c7eec4-f54d-40e7-8073-5886cc372ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "start_date='2021-11-26 00:00:00'\n",
    "end_date='2022-01-26 23:55:00' \n",
    "inputs = ['min_gas_price', 'max_gas_price', 'min_gas_price_24hr_lag', 'Open']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in = 2016\n",
    "n_steps_out = 1\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0ee7f98-0260-491d-a87a-eb854106b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale_y_retrun_metrics():\n",
    "    pred_descaled= (scaler.inverse_transform(array([yhat,]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    groud_truth_descaled= (scaler.inverse_transform(array([y_val,]*(len(inputs))).transpose()[0][0]))[ :, :1]\n",
    "    RMSE = mean_squared_error(groud_truth_descaled, pred_descaled, squared=False)\n",
    "    MAE = mean_absolute_error(groud_truth_descaled, pred_descaled)\n",
    "    MAPE = mean_absolute_percentage_error(groud_truth_descaled, pred_descaled)\n",
    "    R2 = r2_score(groud_truth_descaled, pred_descaled)\n",
    "    return RMSE, MAE, MAPE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fabf27ba-0c7c-4c8b-82fb-2fb6938e5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 10s 65ms/step\n",
      "146/146 [==============================] - 10s 64ms/step\n",
      "146/146 [==============================] - 10s 65ms/step\n",
      "146/146 [==============================] - 10s 65ms/step\n",
      "146/146 [==============================] - 10s 65ms/step\n",
      "146/146 [==============================] - 10s 65ms/step\n",
      "146/146 [==============================] - 10s 64ms/step\n",
      "146/146 [==============================] - 10s 64ms/step\n",
      "146/146 [==============================] - 10s 64ms/step\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at Direct_Multivariate_Ensemble, n_outputs=1/10_step_lookahead_Direct_Multivariate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30616/4231236719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mn_step_lookahead\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Direct_Multivariate_Ensemble, n_outputs=1/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_step_lookahead_Direct_Multivariate'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_training_val_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file or directory found at {filepath_str}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at Direct_Multivariate_Ensemble, n_outputs=1/10_step_lookahead_Direct_Multivariate"
     ]
    }
   ],
   "source": [
    "RMSE_list, MAE_list, MAPE_list, R2_list = [],[],[],[]\n",
    "for i in range(1,19):\n",
    "    n_step_lookahead = i\n",
    "    model = keras.models.load_model('Direct_Multivariate_Ensemble, n_outputs=1/' + str(i) +'_step_lookahead_Direct_Multivariate' )\n",
    "    X_train, y_train, X_val, y_val = generate_training_val_examples()\n",
    "    yhat = model.predict(X_val, verbose=1)\n",
    "    RMSE, MAE, MAPE, R2 = descale_y_retrun_metrics()\n",
    "    RMSE_list.append(RMSE)\n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "    R2_list.append(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b73c35d-df05-48de-90d8-428ce592aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0278964487451475e-08,\n",
       " 4.923146750528344e-08,\n",
       " 5.063530975809405e-08,\n",
       " 5.199729183768327e-08,\n",
       " 5.593486080804972e-08,\n",
       " 5.4786724074945016e-08,\n",
       " 5.423113120494018e-08,\n",
       " 5.551279700350256e-08,\n",
       " 6.222864067640287e-08]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2addab02-b732-4027-9a9b-6eb01512551f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12471274781395766,\n",
       " 0.18563279217381598,\n",
       " 0.18700806022354385,\n",
       " 0.164386620446668,\n",
       " 0.22778246758310786,\n",
       " 0.21044326533314667,\n",
       " 0.1928804145287867,\n",
       " 0.19950499581359143,\n",
       " 0.3041528904611323]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPE_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9e7b3-9159-41c2-84d6-acb185b09414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
