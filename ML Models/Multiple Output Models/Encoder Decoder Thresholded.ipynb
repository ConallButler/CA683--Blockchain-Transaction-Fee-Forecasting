{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed254beb-b30d-40dd-b1ab-1675290adaa0",
   "metadata": {},
   "source": [
    "# Encoder Decoder; Min gas thresholded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cf8a4-056b-49a8-8123-cc15d8f2f71b",
   "metadata": {},
   "source": [
    "We are training a seperate model for each timestep in the lookahead window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2243fdcb-c389-4556-be27-9373234fc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd68e3ae-22e3-43af-b5e2-abdca3c87420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead):\n",
    "    X, y = list(), list()\n",
    "    example_count = int((len(sequence)/step_interval))\n",
    "    for i in range(example_count):\n",
    "        # find the end of this pattern\n",
    "        end_ix = (i*step_interval) + n_steps_in\n",
    "        out_start_ix = end_ix + n_step_lookahead -1\n",
    "        out_end_ix = end_ix + n_steps_out + n_step_lookahead -1\n",
    "        # check if we are beyond the sequence\n",
    "        if out_end_ix > len(sequence):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[(i*step_interval):end_ix], sequence[out_start_ix:out_end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "479cb03e-33f8-4df8-afe6-82b2351713ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4],\n",
       "        [1, 2, 3, 4, 5],\n",
       "        [2, 3, 4, 5, 6],\n",
       "        [3, 4, 5, 6, 7]]),\n",
       " array([[ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To demonstrate above function\n",
    "sequence = range(0,13)\n",
    "n_steps_in = 1\n",
    "n_steps_in = 5\n",
    "n_steps_out =1\n",
    "step_interval =1\n",
    "n_step_lookahead=5\n",
    "split_sequence(sequence, n_steps_in, n_steps_out, step_interval, n_step_lookahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82378d09-0115-4a36-8af6-dc72a20cdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_thresholded(feature, data):\n",
    "    data_mean, data_std = mean(data[feature]), std(data[feature])\n",
    "    cut_off = data_std * 2\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    for index,row in data.iterrows():\n",
    "      if row[feature] < lower:\n",
    "        row[feature]=lower\n",
    "      elif row[feature] > upper:\n",
    "        row[feature]=upper\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d5c8f-ec30-4918-bd5a-026cbb636357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498cbb83-dab4-4707-8187-a389d8ea418b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9123a9bf",
   "metadata": {},
   "source": [
    "Load data, datetime to index, downsample with left edge label, convert wei to gwei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ac449a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples():\n",
    "    #Load data as float, datetime to index\n",
    "    data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    data = data.set_index('datetime')\n",
    "    data = data.squeeze()\n",
    "    data = data.astype('float')\n",
    "\n",
    "    #Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "    data = data.resample(resample_rate).mean()\n",
    "\n",
    "    \n",
    "     #Add 24hr lag for min gas price\n",
    "    data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "    data = data[288:]\n",
    "    \n",
    "    #Set outlier limit\n",
    "    for i in inputs:\n",
    "        data = outliers_thresholded(i, data)\n",
    "    \n",
    "\n",
    "    #Filter inputs, Scale \n",
    "    data =data[inputs]\n",
    "    scaler = MinMaxScaler()\n",
    "    data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    y = y[:, :, :1]\n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4b17f-e5fa-414a-8620-452ef4d893bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "34d8e23f-0232-4580-abc7-f2bae6d359e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Examples for all lookaheads\n",
    "resample_rate = '5T'\n",
    "start_date='2021-11-26 00:00:00'\n",
    "end_date='2022-01-26 23:55:00' \n",
    "inputs = ['min_gas_price', 'max_gas_price', 'min_gas_price_24hr_lag', 'Open']\n",
    "#No of timesteps behind to forecast on, no of timesteps to forecast ahead\n",
    "n_steps_in =  2016\n",
    "n_steps_out = 12\n",
    "#How many timesteps between start of training examples\n",
    "step_interval = 1\n",
    "n_step_lookahead = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "095b220a-aabf-4ec1-a280-db969a29e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = generate_training_val_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f07cd239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "109/109 [==============================] - 91s 681ms/step - loss: 0.0379 - val_loss: 0.0467\n",
      "Epoch 2/10\n",
      "109/109 [==============================] - 71s 649ms/step - loss: 0.0196 - val_loss: 0.0253\n",
      "Epoch 3/10\n",
      "109/109 [==============================] - 71s 648ms/step - loss: 0.0164 - val_loss: 0.0230\n",
      "Epoch 4/10\n",
      "109/109 [==============================] - 71s 650ms/step - loss: 0.0154 - val_loss: 0.0210\n",
      "Epoch 5/10\n",
      "109/109 [==============================] - 70s 646ms/step - loss: 0.0145 - val_loss: 0.0217\n",
      "Epoch 6/10\n",
      "109/109 [==============================] - 72s 657ms/step - loss: 0.0143 - val_loss: 0.0204\n",
      "Epoch 7/10\n",
      "109/109 [==============================] - 71s 656ms/step - loss: 0.0141 - val_loss: 0.0204\n",
      "Epoch 8/10\n",
      " 11/109 [==>...........................] - ETA: 51s - loss: 0.0154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18940/4163815576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs)), return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', input_shape=(n_steps_in, len(inputs))))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(units=1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=10, verbose=1, batch_size=100, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4a79ee3c-c389-4517-90c3-66dac8d51201",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses, lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder_decoder_12_thresholded\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder_decoder_12_thresholded\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002498D9A1D30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002498E1B1220> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002498E2012B0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002499187BF10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000024993A3DDF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x00000249948864C0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000024994BACAC0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000024994DE4070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002499505AEE0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('encoder_decoder_12_thresholded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a3aaef",
   "metadata": {},
   "source": [
    "## Evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ec655c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c96be238-7c7e-45d2-b963-d4d0519a03a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 40s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f745f51a-7fab-4cf1-b5a2-dd422e381f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics(y_val, y_pred):\n",
    "    RMSE = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    MAE = mean_absolute_error(y_val, y_pred)\n",
    "    MAPE = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    R2 = r2_score(y_val, y_pred)\n",
    "    MSE = mean_squared_error(y_val, y_pred)\n",
    "    return RMSE, MAE, MAPE, R2, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "049bed69-a202-4889-b334-488d430fbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our min max scaler so we can revert transform\n",
    "#Load data as float, datetime to index\n",
    "#Load data as float, datetime to index\n",
    "data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "data = data.set_index('datetime')\n",
    "data = data.squeeze()\n",
    "data = data.astype('float')\n",
    "\n",
    "#Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "data = data.resample(resample_rate).mean()\n",
    "\n",
    "    \n",
    "#Add 24hr lag for min gas price\n",
    "data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "data = data[288:]\n",
    "    \n",
    "#Set outlier limit\n",
    "for i in inputs:\n",
    "    data = outliers_thresholded(i, data)\n",
    "    \n",
    "\n",
    "#Filter inputs, Scale \n",
    "data =data[inputs]\n",
    "scaler = MinMaxScaler()\n",
    "data[inputs] = scaler.fit_transform(data[inputs])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b642b42e-5bc7-4790-a0da-d8ce69161c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "for i in range(0, len(y_val)):\n",
    "    pred_descaled= (scaler.inverse_transform(array([yhat[i],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    val_descaled= (scaler.inverse_transform(array([y_val[i],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    RMSE, MAE, MAPE, R2, MSE = return_metrics((val_descaled), (pred_descaled))\n",
    "    RMSE_list.append(RMSE)\n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "    R2_list.append(R2)\n",
    "    MSE_list.append(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "be1019c2-8725-4d6a-a35c-9faa858484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_RMSE 33.08741830117068\n",
      "mean_MAE 29.753615534783247\n",
      "mean_MAPE 0.23471605569308118\n",
      "mean_R2 -3.884154610419752e+26\n"
     ]
    }
   ],
   "source": [
    "print('mean_RMSE ' + str(mean(RMSE_list))) \n",
    "print('mean_MAE ' + str(mean(MAE_list))) \n",
    "print('mean_MAPE ' + str(mean(MAPE_list)))\n",
    "print('mean_R2 ' + str(mean(R2_list)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64608d7-1a2c-4100-a36d-ce26b82e298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_thresholded(feature, data):\n",
    "    data_mean, data_std = mean(data[feature]), std(data[feature])\n",
    "    cut_off = data_std * 2\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    for index,row in data.iterrows():\n",
    "      if row[feature] < lower:\n",
    "        row[feature]=lower\n",
    "      elif row[feature] > upper:\n",
    "        row[feature]=upper\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76eb23b7-fc53-4be6-81fb-1d3e9b63c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_no_thresh():\n",
    "    #Load data as float, datetime to index\n",
    "    data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    data = data.set_index('datetime')\n",
    "    data = data.squeeze()\n",
    "    data = data.astype('float')\n",
    "\n",
    "    #Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "    data = data.resample(resample_rate).mean()\n",
    "\n",
    "    \n",
    "     #Add 24hr lag for min gas price\n",
    "    data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "    data = data[288:]\n",
    "    \n",
    " \n",
    "    \n",
    "\n",
    "    #Filter inputs, Scale \n",
    "    data =data[inputs]\n",
    "\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    y = y[:, :, :1]\n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75f1ea73-b360-4aa5-939e-66994eabc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, y_train2, X_val2, y_val2 = generate_training_val_examples_no_thresh() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a2e66f13-0506-4ff0-b977-48e518f4cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_list, MAE_list, MAPE_list, R2_list, MSE_list = [],[],[],[],[]\n",
    "for i in range(0, len(y_val)):\n",
    "    pred_descaled= (scaler.inverse_transform(array([yhat[i],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "    RMSE, MAE, MAPE, R2, MSE = return_metrics((y_val2[i]), (pred_descaled*1000000000))\n",
    "    RMSE_list.append(RMSE)\n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "    R2_list.append(R2)\n",
    "    MSE_list.append(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60301410-9a07-492e-bc79-1bdc37e1e552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_RMSE 34.61227458614174\n",
      "mean_MAE 27.160770241910676\n",
      "mean_MAPE 0.17230442706705165\n",
      "mean_R2 -1.9373244759557138\n"
     ]
    }
   ],
   "source": [
    "print('mean_RMSE ' + str(mean(RMSE_list))) \n",
    "print('mean_MAE ' + str(mean(MAE_list))) \n",
    "print('mean_MAPE ' + str(mean(MAPE_list)))\n",
    "print('mean_R2 ' + str(mean(R2_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ef0828c-2920-4760-8bfb-5354fe30d1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173.8338214285714"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "15cbd48f-d8ec-4b25-9305-d2bb2242b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241.0422666666666"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_descaled= (scaler.inverse_transform(array([y_val[8],]*(len(inputs))).transpose()[0]))[:, :1]\n",
    "(val_descaled*1000000000).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89526ad-35e5-46c6-ae40-be0817c39bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_thresholded(feature, data):\n",
    "    data_mean, data_std = mean(data[feature]), std(data[feature])\n",
    "    cut_off = data_std * 2\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    for index,row in data.iterrows():\n",
    "      if row[feature] < lower:\n",
    "        row[feature]=lower\n",
    "      elif row[feature] > upper:\n",
    "        row[feature]=upper\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bb2a0f7b-3b18-4a9f-87f8-fc91f1ce2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_val_examples_no_min_max():\n",
    "    #Load data as float, datetime to index\n",
    "    data = pd.read_csv (r'C:\\Users\\conal\\Desktop\\MCM\\Practicum\\data\\ETH,gas,usage merged 11-26 to 01-26.csv', header=0)\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    data = data.set_index('datetime')\n",
    "    data = data.squeeze()\n",
    "    data = data.astype('float')\n",
    "\n",
    "    #Resample with left edge label i.e min 1-5 mean labelled as min1\n",
    "    data = data.resample(resample_rate).mean()\n",
    "\n",
    "    \n",
    "     #Add 24hr lag for min gas price\n",
    "    data['min_gas_price_24hr_lag'] = data['min_gas_price'].shift(288)\n",
    "    data = data[288:]\n",
    "    \n",
    "    #Set outlier limit\n",
    "    for i in inputs:\n",
    "        data = outliers_thresholded(i, data)\n",
    "    \n",
    "\n",
    "    #Filter inputs, Scale \n",
    "    data =data[inputs]\n",
    "\n",
    "    \n",
    "\n",
    "    #Creat input:output examples\n",
    "    data = data[start_date:end_date].to_numpy()\n",
    "    X, y = split_sequence(data, n_steps_in, n_steps_out, step_interval, n_step_lookahead)\n",
    "    y = y[:, :, :1]\n",
    "    X_train, X_val = np.split(X, [int(0.7 * len(X))])\n",
    "    #we are only lookign to forecast the min gas price\n",
    "    y_train, y_val = np.split(y, [int(0.7 * len(X))])\n",
    "\n",
    "    \n",
    "    #Reshape to 3D for LSTM\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], len(inputs)))\n",
    "    y_train =y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], len(inputs)))\n",
    "    y_val = y_val.reshape((y_val.shape[0], y_val.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8eec100-639e-41eb-b318-e1d4074625ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, y_train3, X_val3, y_val3=generate_training_val_examples_no_min_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9bee7c36-c867-477b-835d-717ff0e1cb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.41319339294142"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c58158-46dc-454a-9fa5-e1c25c0e8e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
